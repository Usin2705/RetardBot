# RetardBot
Reddit's WallStreetBet comment generation project<br>
Team members: Nhan Phan, Ryoko Noda.

## About the project
This project was done for Aalto University's Statistical Natural Language Processing course. 
The project report can be found [here](https://github.com/Usin2705/RetardBot/blob/master/Project_Report.pdf).

The repository contains the codes and data we used to create four language models that replicates the posts from Reddit's [WallStreetBets](https://www.reddit.com/r/wallstreetbets/).
Once put together, the models should be able to generate somewhat WallStreetBets-like sentences like the ones below. 
These are real sentences generated by our Bi-LSTM model, which we posted on Reddit as an example (the post have been removed by us):

<img src="https://github.com/Usin2705/RetardBot/blob/master/illustration/sample_post_for_readme.png" width="600">
Files here are mainly of four categories:

1. The datasets
1. Codes to scrape the dataset
1. Notebook for data cleaning
1. Notebooks for language models

The repository contains codes we used for experimental purposes before finalizing the project. The codes we used in the final version are:

* [WSBpmaw.py](https://github.com/Usin2705/RetardBot/blob/master/WSBpmaw.py)
* [step_01_data_preprocessing.ipynb](https://github.com/Usin2705/RetardBot/blob/master/step_01_data_preprocessing.ipynb)
* [step_02_ngrams.ipynb](https://github.com/Usin2705/RetardBot/blob/master/step_02_ngrams.ipynb)
* [step_03_RNN.ipynb](https://github.com/Usin2705/RetardBot/blob/master/step_03_RNN.ipynb)

## The datasets
The datasets scraped from WallStreetBets can be found in the [data](https://github.com/Usin2705/RetardBot/tree/master/data) folder.
This folder contains datasets of various lengths (+ one dataset that we used in an experiment that is not from WallStreetBets).
The 2 years dataset size is 63MB and contain about 850,000 sentences was not uploaded to Github.

__data_sample.txt:__ The sample dataset, 20,000 sentences.<br>
__data_sample_2x.txt:__ Double the size of sample dataset, 40,000 sentences. This is our main dataset for the project report<br>
__data_sample_4x.txt:__ Another bigger dataset, containing 80,000 sentences. We have several bigger size dataset (that were not upload) to test the limit of our hardware <br>
__data_sample_test.txt:__ A very small dataset of 1,000 sentences. Can be used for tests.<br>
__reddit-cleanjokes.csv__: A dataset used to run the sample LSTM models. NOT FROM WALLSTREETBETS.

## Web scraping codes
There are two web scraping codes, one of which we abandoned after we found Pushshift.

__WSBpmaw.py:__ The code used in the final version, which uses the Pushshift wrapper [PMAW](https://github.com/mattpodolak/pmaw).<br>
__WSBPraw.py:__ The code that uses the more popular [PRAW](https://praw.readthedocs.io/en/latest/). This is useful for downloading live data but not historical data so it was not used in our project.

## Data preprocessing
There is only one file that we used when preprocessing the data.

__[step_01_data_preprocessing.ipynb](https://github.com/Usin2705/RetardBot/blob/master/step_01_data_preprocessing.ipynb):__ Preprocesses the WallStreetBets datasets.

## Language models
We tried four models in this project: n-grams, GRU, LSTM, and Bi-LSTM. 
The n-grams model has a Jupyter notebook to itself, and the GRU, LSTM, and Bi-LSTM models can be found in a generic RNN notebook in which you can choose what model to use.

__[step_02_ngrams.ipynb](https://github.com/Usin2705/RetardBot/blob/master/step_02_ngrams.ipynb):__ The n-grams code for the final version. It contains 5-grams with absolute smoothing.<br>
__[step_03_RNN.ipynb](https://github.com/Usin2705/RetardBot/blob/master/step_03_RNN.ipynb):__ The generic RNN model used in the final version. You can choose GRU, LSTM, or Bi-LSTM within the notebook.<br>
__[test_LSTM_kdnuggets.ipynb](https://github.com/Usin2705/RetardBot/blob/master/test_LSTM_kdnuggets.ipynb):__ [A LSTM model from KDnuggets](https://www.kdnuggets.com/2020/07/pytorch-lstm-text-generation-tutorial.html) that we used to learn what LSTM is like.<br>
__[test_LSTM_kdn_preprocess.ipynb](https://github.com/Usin2705/RetardBot/blob/master/test_LSTM_kdn_preprocess.ipynb):__ An experimental model where we added some data preprocessing to test_LSTM_kdnuggets.ipynb.
