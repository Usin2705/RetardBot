{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "LSTM_kdn_preprocess.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwMoK7If86mX"
      },
      "source": [
        "# The LSTM model shown in the KDnuggets article\n",
        "\n",
        "https://www.kdnuggets.com/2020/07/pytorch-lstm-text-generation-tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aldZUwUz86mZ"
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from torch.utils.data import DataLoader\n",
        "import re, string\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNi2QLnC-Kuf",
        "outputId": "c525ef17-5b01-4516-9755-aede6b454c82"
      },
      "source": [
        "# this is to connect this notebook to the contents of your Google Drive\n",
        "# files uploaded to Google Drive will not be deleted by inactivity,\n",
        "# but it does require an authorization code every time you use it\n",
        "from google.colab import drive\n",
        "drive.mount(r'/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LnKyN44_25w"
      },
      "source": [
        "# this is Ryoko's Google Drive filepath\n",
        "# please specify your own, or we can (probably) share a folder for it\n",
        "filepath = r'/content/drive/My Drive/RetardBot/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTRefLnj86mb"
      },
      "source": [
        "is_training = True\n",
        "\n",
        "#this is for saving/loading the model from the checkpoint when colab crashes\n",
        "load_model  = True\n",
        "load_file = \"kdn_temp2\" #file name if I'm going to load the model\n",
        "tmp_name = \"kdn_temp2\" #temporary file I want to create checkpoint in\n",
        "\n",
        "#the device switch\n",
        "device = torch.device('cuda:0')\n",
        "#device = torch.device('cpu')\n",
        "\n",
        "#parameters needed to run the model\n",
        "#these originally needed to be specified from the terminal\n",
        "sequence_length = 4 #Default = 4 \n",
        "batch_size = 128 #Default = 256 Reduce if PC don't have enough RAM\n",
        "max_epochs = 400 #Default = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWp9TaJV86mb"
      },
      "source": [
        "### Notes on the model architecture\n",
        "\n",
        "Based on model from https://www.kdnuggets.com/2020/07/pytorch-lstm-text-generation-tutorial.html\n",
        "\n",
        "The model has three components:\n",
        "1. **Embedding layer:** converts input of size (batch_size, sequence_length) to embedding of size (batch_size, sequence_length, embedding_dim)\n",
        "2. **Stacked LSTM of 3 layers:** accepts embedding and a tuple (previous hidden state, previous cell state) and gives an output of size (batch_size, sequence_length, embedding_dim) and the tuple (current hidden state, current cell state). The hidden state and cell state both have size (num_layers, sequence_length, embedding_dim).\n",
        "3. **Linear layer:** Maps the output of LSTM to logits for each word in vocab. Not a probability yet. Output size is  (batch_size, sequence_length, vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipp87kCB86mc"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, dataset):\n",
        "        super(Model, self).__init__()\n",
        "        self.lstm_size = 128\n",
        "        self.embedding_dim = 128\n",
        "        self.num_layers = 3 #stack 3 LSTM layers for abstract representation\n",
        "\n",
        "        n_vocab = len(dataset.uniq_words)\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.lstm_size,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.1,\n",
        "        )\n",
        "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        logits = self.fc(output)\n",
        "        return logits, state\n",
        "\n",
        "    def init_state(self, sequence_length):\n",
        "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size).to(device),\n",
        "                torch.zeros(self.num_layers, sequence_length, self.lstm_size).to(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jorh-klW86md"
      },
      "source": [
        "### Notes on the custom dataset\n",
        "\n",
        "According to the Pytorch documentation, a custom dataset needs at least the functions \\_\\_len\\_\\_ and \\_\\_getitem\\_\\_. \\_\\_len\\_\\_\\_ allows len(dataset) to return the size of the dataset and  \\_\\_getitem\\_\\_ allows the ith element of the dataset to be fetched with dataset\\[i\\].\n",
        "\n",
        "In this custom dataset, \\_\\_len\\_\\_ and \\_\\_getitem\\_\\_ are designed like this. Let's say the only sentence we have in the dataset is:\n",
        "\n",
        "__*We are using LSTM to create the Retard-bot language model.*__\n",
        "\n",
        "__\\_\\_len\\_\\_:__<br>\n",
        "For this custom dataset it's defined as \"the size of the dataset - sequence length\". This is probably because this model is created to make predictions based the first 4 words (default sequence length) given as prompt, but I can't say for certain. So in the example sentence above, it will return  the length of \"**to create the Retard-bot language model.**\"\n",
        "\n",
        "__\\_\\_getitem\\_\\_:__<br>\n",
        "It seems that this returns a tuple of n-grams with the n defined by sequence length. So if we say dataset\\[0\\] in the simple example, we would get (**We are using LSTM**, **are using LSTM to**). Not sure why it does this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjLxQzLJLc-p"
      },
      "source": [
        "def preprocess(filename, clip=1):\n",
        "  f = open(filename, \"r\")\n",
        "  text = f.read()\n",
        "  \n",
        "\n",
        "  text = text.split(' ')\n",
        "  text = [word for word in text if not '\\\\' in r\"%r\" %word] #remove the words containing backslashes (formerly emojis or sth?)\n",
        "  text = [word.lower() for word in text] \n",
        "  text =  [WordPunctTokenizer().tokenize(word) for word in text] #using nltk to separate punctuation from words\n",
        "  text = [item for sublist in text for item in sublist]\n",
        "\n",
        "  #if passed, clip shortens the text to 1/clip of the original\n",
        "  clip_idx = round(len(text) / clip)\n",
        "  text = text[:clip_idx]\n",
        "  \n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYCe9N3N86me"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        sequence_length\n",
        "    ):\n",
        "        \"\"\"\n",
        "        words:                 words in entire dataset split by whitespace\n",
        "        uniq_words:       the unique words sorted by frequency (most frequent first)\n",
        "        index_to_word: index to word dict {index0: word0, index1:word1...}, most frequent have smaller index\n",
        "        word_to_index: word to index dict {word0: index0, word1:index1...}, most frequent have smaller index\n",
        "        words_indexes:  the words converted to their indices using word_to_index\n",
        "        \"\"\"\n",
        "        self.sequence_length = sequence_length\n",
        "        self.words = self.load_words()\n",
        "        self.uniq_words = self.get_uniq_words()\n",
        "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
        "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
        "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
        "        \n",
        "    def load_words(self):\n",
        "        #train_df = pd.read_csv('reddit-cleanjokes.csv') #original reddit-jokes dataset\n",
        "        #text = train_df['Joke'].str.cat(sep=' ')\n",
        "        return preprocess(filepath+\"clean_data.txt\", clip=15)\n",
        "    \n",
        "    def get_uniq_words(self):\n",
        "        word_counts = Counter(self.words)\n",
        "        return sorted(word_counts, key=word_counts.get, reverse=True) \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.words_indexes) - self.sequence_length\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
        "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anb85jBK86mf"
      },
      "source": [
        "dataset = Dataset(sequence_length)\n",
        "model = Model(dataset)\n",
        "model = model.to(device)\n",
        "tmp_name = \"kdn_temp2\"\n",
        "\n",
        "def train(dataset, model):\n",
        "    model.train()\n",
        "    \n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle = True) # NEED TO SHUFFLE AND RERUN\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    lambda1 = lambda epoch: 0.8 ** epoch\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
        "\n",
        "    if load_model == True:\n",
        "      checkpoint = torch.load(filepath+load_file, map_location=device)\n",
        "      model.load_state_dict(checkpoint['model_state_dict'])\n",
        "      optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "      last_epoch = checkpoint['epoch']\n",
        "      epoch_losses = checkpoint['epoch_losses']\n",
        "    else:\n",
        "      last_epoch = 0\n",
        "      epoch_losses = []\n",
        "    \n",
        "    for epoch in range(last_epoch, max_epochs):\n",
        "      epoch_loss = 0.0\n",
        "      state_h, state_c = model.init_state(sequence_length)\n",
        "      \n",
        "      for i, batch in enumerate(dataloader):\n",
        "          x, y = batch\n",
        "          x, y = x.to(device), y.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "          loss = criterion(y_pred.transpose(1, 2), y)\n",
        "          \n",
        "          state_h = state_h.detach()\n",
        "          state_c = state_c.detach()\n",
        "          \n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          epoch_loss += loss.item()\n",
        "          \n",
        "\n",
        "          if (i +1)% 100 ==0:\n",
        "            print({ 'epoch': epoch+1, \"batch\": i+1, 'loss': epoch_loss/(i+1) })\n",
        "      \n",
        "      print({ 'epoch': epoch+1, 'loss': epoch_loss/(i+1), 'epoch_losses len': len(epoch_losses)})\n",
        "\n",
        "      if (epoch+1)%10 == 0:\n",
        "        print(\"decrease learning rate\")\n",
        "        scheduler.step()\n",
        "\n",
        "      # this is needed for work in Colab because once the time limit is up,\n",
        "      # it will automatically delete all files that are not saved in Google Drive      \n",
        "      print(\"saving model\")\n",
        "      torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'epoch_losses': epoch_losses,\n",
        "            }, filepath + tmp_name)\n",
        "      epoch_losses.append(epoch_loss)\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiIa1Hw786mg"
      },
      "source": [
        "def predict(dataset, model, text, next_words=100):\n",
        "    model.eval()\n",
        "    \n",
        "    words = text.split(' ')\n",
        "    state_h, state_c = model.init_state(len(words))\n",
        "    \n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]], device=device)\n",
        "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "        \n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().cpu().numpy()\n",
        "        p /= p.sum() #this is to avoid an error numpy gives about probability not summing to 1\n",
        "        \n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.index_to_word[word_index])\n",
        "        \n",
        "    return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxKHjChc86mg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "264e1b48-d620-4ff3-f4df-3c164231447b"
      },
      "source": [
        "if is_training:\n",
        "    train(dataset, model)\n",
        "    #file_name = 'kdnuggets' + str(max_epochs)\n",
        "    file_name = 'kdnuggets_preprocess_' + str(max_epochs)\n",
        "    torch.save(model.state_dict(), filepath+file_name)\n",
        "else:\n",
        "    #model.load_state_dict(torch.load(file_name, map_location=lambda storage, loc: storage))\n",
        "    model.load_state_dict(torch.load(filepath + 'kdnuggets_temp',map_location=torch.device('cpu')))\n",
        "    model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'batch': 100, 'loss': 4.97307436466217}\n",
            "{'epoch': 9, 'batch': 200, 'loss': 4.985718533992768}\n",
            "{'epoch': 9, 'batch': 300, 'loss': 4.989361406962077}\n",
            "{'epoch': 9, 'batch': 400, 'loss': 4.993049536943436}\n",
            "{'epoch': 9, 'batch': 500, 'loss': 4.992406661987305}\n",
            "{'epoch': 9, 'batch': 600, 'loss': 4.992355169455211}\n",
            "{'epoch': 9, 'batch': 700, 'loss': 4.991387325695583}\n",
            "{'epoch': 9, 'batch': 800, 'loss': 4.993124195933342}\n",
            "{'epoch': 9, 'batch': 900, 'loss': 4.991148814095391}\n",
            "{'epoch': 9, 'batch': 1000, 'loss': 4.992438296794892}\n",
            "{'epoch': 9, 'batch': 1100, 'loss': 4.994581370353699}\n",
            "{'epoch': 9, 'batch': 1200, 'loss': 4.99402241786321}\n",
            "{'epoch': 9, 'batch': 1300, 'loss': 4.993597203034621}\n",
            "{'epoch': 9, 'batch': 1400, 'loss': 4.99409601518086}\n",
            "{'epoch': 9, 'batch': 1500, 'loss': 4.996076333999634}\n",
            "{'epoch': 9, 'batch': 1600, 'loss': 4.997355302274227}\n",
            "{'epoch': 9, 'batch': 1700, 'loss': 4.996597643179052}\n",
            "{'epoch': 9, 'batch': 1800, 'loss': 4.997361216280195}\n",
            "{'epoch': 9, 'batch': 1900, 'loss': 4.998117971420288}\n",
            "{'epoch': 9, 'batch': 2000, 'loss': 4.997725254058838}\n",
            "{'epoch': 9, 'batch': 2100, 'loss': 4.998946854046413}\n",
            "{'epoch': 9, 'batch': 2200, 'loss': 4.998795912049033}\n",
            "{'epoch': 9, 'batch': 2300, 'loss': 4.99955626529196}\n",
            "{'epoch': 9, 'batch': 2400, 'loss': 5.0004100962479905}\n",
            "{'epoch': 9, 'batch': 2500, 'loss': 5.000611088371277}\n",
            "{'epoch': 9, 'batch': 2600, 'loss': 4.999983200660119}\n",
            "{'epoch': 9, 'batch': 2700, 'loss': 5.000072539470814}\n",
            "{'epoch': 9, 'batch': 2800, 'loss': 5.000639103821346}\n",
            "{'epoch': 9, 'batch': 2900, 'loss': 5.001439455788711}\n",
            "{'epoch': 9, 'batch': 3000, 'loss': 5.001504747708639}\n",
            "{'epoch': 9, 'batch': 3100, 'loss': 5.001588089543004}\n",
            "{'epoch': 9, 'batch': 3200, 'loss': 5.001291421502828}\n",
            "{'epoch': 9, 'batch': 3300, 'loss': 5.001705321832136}\n",
            "{'epoch': 9, 'batch': 3400, 'loss': 5.001875689871171}\n",
            "{'epoch': 9, 'batch': 3500, 'loss': 5.001590906143188}\n",
            "{'epoch': 9, 'batch': 3600, 'loss': 5.001684395737118}\n",
            "{'epoch': 9, 'batch': 3700, 'loss': 5.0016570712424615}\n",
            "{'epoch': 9, 'batch': 3800, 'loss': 5.001552340984344}\n",
            "{'epoch': 9, 'batch': 3900, 'loss': 5.001747514895904}\n",
            "{'epoch': 9, 'batch': 4000, 'loss': 5.001939797282219}\n",
            "{'epoch': 9, 'batch': 4100, 'loss': 5.002103344289268}\n",
            "{'epoch': 9, 'batch': 4200, 'loss': 5.0018212355886185}\n",
            "{'epoch': 9, 'batch': 4300, 'loss': 5.002276039123535}\n",
            "{'epoch': 9, 'batch': 4400, 'loss': 5.00204562349753}\n",
            "{'epoch': 9, 'batch': 4500, 'loss': 5.001649190796746}\n",
            "{'epoch': 9, 'batch': 4600, 'loss': 5.0021247544495955}\n",
            "{'epoch': 9, 'batch': 4700, 'loss': 5.0023209605318435}\n",
            "{'epoch': 9, 'batch': 4800, 'loss': 5.002415337065855}\n",
            "{'epoch': 9, 'batch': 4900, 'loss': 5.003026911774461}\n",
            "{'epoch': 9, 'batch': 5000, 'loss': 5.003529905319214}\n",
            "{'epoch': 9, 'loss': 5.003489910912771, 'epoch_losses len': 10}\n",
            "saving model\n",
            "{'epoch': 10, 'batch': 100, 'loss': 4.959620633125305}\n",
            "{'epoch': 10, 'batch': 200, 'loss': 4.961690931320191}\n",
            "{'epoch': 10, 'batch': 300, 'loss': 4.961905929247538}\n",
            "{'epoch': 10, 'batch': 400, 'loss': 4.9574048817157745}\n",
            "{'epoch': 10, 'batch': 500, 'loss': 4.956062559127807}\n",
            "{'epoch': 10, 'batch': 600, 'loss': 4.9596323704719545}\n",
            "{'epoch': 10, 'batch': 700, 'loss': 4.959683132171631}\n",
            "{'epoch': 10, 'batch': 800, 'loss': 4.96161175429821}\n",
            "{'epoch': 10, 'batch': 900, 'loss': 4.965111807717217}\n",
            "{'epoch': 10, 'batch': 1000, 'loss': 4.965654848575592}\n",
            "{'epoch': 10, 'batch': 1100, 'loss': 4.964950447949496}\n",
            "{'epoch': 10, 'batch': 1200, 'loss': 4.965495448112488}\n",
            "{'epoch': 10, 'batch': 1300, 'loss': 4.968615919626676}\n",
            "{'epoch': 10, 'batch': 1400, 'loss': 4.969726526056017}\n",
            "{'epoch': 10, 'batch': 1500, 'loss': 4.971015603383382}\n",
            "{'epoch': 10, 'batch': 1600, 'loss': 4.971814513802529}\n",
            "{'epoch': 10, 'batch': 1700, 'loss': 4.9723145341873165}\n",
            "{'epoch': 10, 'batch': 1800, 'loss': 4.973201720979478}\n",
            "{'epoch': 10, 'batch': 1900, 'loss': 4.974487740868017}\n",
            "{'epoch': 10, 'batch': 2000, 'loss': 4.975247150182724}\n",
            "{'epoch': 10, 'batch': 2100, 'loss': 4.97561490104312}\n",
            "{'epoch': 10, 'batch': 2200, 'loss': 4.975596237616106}\n",
            "{'epoch': 10, 'batch': 2300, 'loss': 4.9758329308551295}\n",
            "{'epoch': 10, 'batch': 2400, 'loss': 4.976268505454064}\n",
            "{'epoch': 10, 'batch': 2500, 'loss': 4.976792960357666}\n",
            "{'epoch': 10, 'batch': 2600, 'loss': 4.976584944541638}\n",
            "{'epoch': 10, 'batch': 2700, 'loss': 4.977737100036056}\n",
            "{'epoch': 10, 'batch': 2800, 'loss': 4.977404228959765}\n",
            "{'epoch': 10, 'batch': 2900, 'loss': 4.977936665271891}\n",
            "{'epoch': 10, 'batch': 3000, 'loss': 4.97778699016571}\n",
            "{'epoch': 10, 'batch': 3100, 'loss': 4.977056882612167}\n",
            "{'epoch': 10, 'batch': 3200, 'loss': 4.976945956349373}\n",
            "{'epoch': 10, 'batch': 3300, 'loss': 4.977331594409365}\n",
            "{'epoch': 10, 'batch': 3400, 'loss': 4.976907771334929}\n",
            "{'epoch': 10, 'batch': 3500, 'loss': 4.977070955276489}\n",
            "{'epoch': 10, 'batch': 3600, 'loss': 4.977258777221044}\n",
            "{'epoch': 10, 'batch': 3700, 'loss': 4.978254584750614}\n",
            "{'epoch': 10, 'batch': 3800, 'loss': 4.9778715536468905}\n",
            "{'epoch': 10, 'batch': 3900, 'loss': 4.977735985731467}\n",
            "{'epoch': 10, 'batch': 4000, 'loss': 4.977928381204605}\n",
            "{'epoch': 10, 'batch': 4100, 'loss': 4.9775834358029245}\n",
            "{'epoch': 10, 'batch': 4200, 'loss': 4.977752987770807}\n",
            "{'epoch': 10, 'batch': 4300, 'loss': 4.977630392118942}\n",
            "{'epoch': 10, 'batch': 4400, 'loss': 4.977667232101614}\n",
            "{'epoch': 10, 'batch': 4500, 'loss': 4.977750852796767}\n",
            "{'epoch': 10, 'batch': 4600, 'loss': 4.9777158057171365}\n",
            "{'epoch': 10, 'batch': 4700, 'loss': 4.977721293023292}\n",
            "{'epoch': 10, 'batch': 4800, 'loss': 4.977797307868799}\n",
            "{'epoch': 10, 'batch': 4900, 'loss': 4.97797325912787}\n",
            "{'epoch': 10, 'batch': 5000, 'loss': 4.97784999332428}\n",
            "{'epoch': 10, 'loss': 4.9778802645583005, 'epoch_losses len': 11}\n",
            "decrease learning rate\n",
            "saving model\n",
            "{'epoch': 11, 'batch': 100, 'loss': 4.925350451469422}\n",
            "{'epoch': 11, 'batch': 200, 'loss': 4.931066575050354}\n",
            "{'epoch': 11, 'batch': 300, 'loss': 4.929223979314168}\n",
            "{'epoch': 11, 'batch': 400, 'loss': 4.9286149311065675}\n",
            "{'epoch': 11, 'batch': 500, 'loss': 4.926061813354492}\n",
            "{'epoch': 11, 'batch': 600, 'loss': 4.928957206408183}\n",
            "{'epoch': 11, 'batch': 700, 'loss': 4.931402595383781}\n",
            "{'epoch': 11, 'batch': 800, 'loss': 4.931090537309647}\n",
            "{'epoch': 11, 'batch': 900, 'loss': 4.932388381958008}\n",
            "{'epoch': 11, 'batch': 1000, 'loss': 4.934250962734223}\n",
            "{'epoch': 11, 'batch': 1100, 'loss': 4.935956137397072}\n",
            "{'epoch': 11, 'batch': 1200, 'loss': 4.936357908646266}\n",
            "{'epoch': 11, 'batch': 1300, 'loss': 4.936706715363723}\n",
            "{'epoch': 11, 'batch': 1400, 'loss': 4.937874555928366}\n",
            "{'epoch': 11, 'batch': 1500, 'loss': 4.939780236244202}\n",
            "{'epoch': 11, 'batch': 1600, 'loss': 4.9395479035377505}\n",
            "{'epoch': 11, 'batch': 1700, 'loss': 4.939736905378454}\n",
            "{'epoch': 11, 'batch': 1800, 'loss': 4.939453961849213}\n",
            "{'epoch': 11, 'batch': 1900, 'loss': 4.940168165909617}\n",
            "{'epoch': 11, 'batch': 2000, 'loss': 4.940493905305862}\n",
            "{'epoch': 11, 'batch': 2100, 'loss': 4.941037407148452}\n",
            "{'epoch': 11, 'batch': 2200, 'loss': 4.941732547283173}\n",
            "{'epoch': 11, 'batch': 2300, 'loss': 4.941274308121723}\n",
            "{'epoch': 11, 'batch': 2400, 'loss': 4.941940083106359}\n",
            "{'epoch': 11, 'batch': 2500, 'loss': 4.9415971353530885}\n",
            "{'epoch': 11, 'batch': 2600, 'loss': 4.942040480650388}\n",
            "{'epoch': 11, 'batch': 2700, 'loss': 4.942356713083055}\n",
            "{'epoch': 11, 'batch': 2800, 'loss': 4.942483965839658}\n",
            "{'epoch': 11, 'batch': 2900, 'loss': 4.943030383175817}\n",
            "{'epoch': 11, 'batch': 3000, 'loss': 4.943574196815491}\n",
            "{'epoch': 11, 'batch': 3100, 'loss': 4.943461648725695}\n",
            "{'epoch': 11, 'batch': 3200, 'loss': 4.943176684975624}\n",
            "{'epoch': 11, 'batch': 3300, 'loss': 4.943288011550903}\n",
            "{'epoch': 11, 'batch': 3400, 'loss': 4.943626085309421}\n",
            "{'epoch': 11, 'batch': 3500, 'loss': 4.943259008271354}\n",
            "{'epoch': 11, 'batch': 3600, 'loss': 4.943056664864222}\n",
            "{'epoch': 11, 'batch': 3700, 'loss': 4.943157101579614}\n",
            "{'epoch': 11, 'batch': 3800, 'loss': 4.943540942919881}\n",
            "{'epoch': 11, 'batch': 3900, 'loss': 4.943138356331067}\n",
            "{'epoch': 11, 'batch': 4000, 'loss': 4.943206124901772}\n",
            "{'epoch': 11, 'batch': 4100, 'loss': 4.943497532053692}\n",
            "{'epoch': 11, 'batch': 4200, 'loss': 4.943575484071459}\n",
            "{'epoch': 11, 'batch': 4300, 'loss': 4.943955493306005}\n",
            "{'epoch': 11, 'batch': 4400, 'loss': 4.9438583261316476}\n",
            "{'epoch': 11, 'batch': 4500, 'loss': 4.944114515516493}\n",
            "{'epoch': 11, 'batch': 4600, 'loss': 4.944094585024792}\n",
            "{'epoch': 11, 'batch': 4700, 'loss': 4.944247880895087}\n",
            "{'epoch': 11, 'batch': 4800, 'loss': 4.944607248604298}\n",
            "{'epoch': 11, 'batch': 4900, 'loss': 4.944821613856725}\n",
            "{'epoch': 11, 'batch': 5000, 'loss': 4.945306683349609}\n",
            "{'epoch': 11, 'loss': 4.945310843844072, 'epoch_losses len': 12}\n",
            "saving model\n",
            "{'epoch': 12, 'batch': 100, 'loss': 4.896994085311889}\n",
            "{'epoch': 12, 'batch': 200, 'loss': 4.903819200992584}\n",
            "{'epoch': 12, 'batch': 300, 'loss': 4.905124753316244}\n",
            "{'epoch': 12, 'batch': 400, 'loss': 4.905576802492142}\n",
            "{'epoch': 12, 'batch': 500, 'loss': 4.906093509674072}\n",
            "{'epoch': 12, 'batch': 600, 'loss': 4.908100835482279}\n",
            "{'epoch': 12, 'batch': 700, 'loss': 4.911338376998901}\n",
            "{'epoch': 12, 'batch': 800, 'loss': 4.9117684650421145}\n",
            "{'epoch': 12, 'batch': 900, 'loss': 4.915156233575609}\n",
            "{'epoch': 12, 'batch': 1000, 'loss': 4.916966079711914}\n",
            "{'epoch': 12, 'batch': 1100, 'loss': 4.915751775828275}\n",
            "{'epoch': 12, 'batch': 1200, 'loss': 4.917558906078338}\n",
            "{'epoch': 12, 'batch': 1300, 'loss': 4.918800018750704}\n",
            "{'epoch': 12, 'batch': 1400, 'loss': 4.919797013146536}\n",
            "{'epoch': 12, 'batch': 1500, 'loss': 4.920285811742147}\n",
            "{'epoch': 12, 'batch': 1600, 'loss': 4.920864188373089}\n",
            "{'epoch': 12, 'batch': 1700, 'loss': 4.921796413589926}\n",
            "{'epoch': 12, 'batch': 1800, 'loss': 4.921666797267066}\n",
            "{'epoch': 12, 'batch': 1900, 'loss': 4.921684317086872}\n",
            "{'epoch': 12, 'batch': 2000, 'loss': 4.921356540679931}\n",
            "{'epoch': 12, 'batch': 2100, 'loss': 4.921684401375907}\n",
            "{'epoch': 12, 'batch': 2200, 'loss': 4.9215534463795745}\n",
            "{'epoch': 12, 'batch': 2300, 'loss': 4.92130221636399}\n",
            "{'epoch': 12, 'batch': 2400, 'loss': 4.92210769156615}\n",
            "{'epoch': 12, 'batch': 2500, 'loss': 4.922867179298401}\n",
            "{'epoch': 12, 'batch': 2600, 'loss': 4.922712201521946}\n",
            "{'epoch': 12, 'batch': 2700, 'loss': 4.922870376021773}\n",
            "{'epoch': 12, 'batch': 2800, 'loss': 4.922483407940184}\n",
            "{'epoch': 12, 'batch': 2900, 'loss': 4.922941675186157}\n",
            "{'epoch': 12, 'batch': 3000, 'loss': 4.9227933648427324}\n",
            "{'epoch': 12, 'batch': 3100, 'loss': 4.92314481289156}\n",
            "{'epoch': 12, 'batch': 3200, 'loss': 4.923195802569389}\n",
            "{'epoch': 12, 'batch': 3300, 'loss': 4.922663229595531}\n",
            "{'epoch': 12, 'batch': 3400, 'loss': 4.9229344408652365}\n",
            "{'epoch': 12, 'batch': 3500, 'loss': 4.923412611825126}\n",
            "{'epoch': 12, 'batch': 3600, 'loss': 4.9236554973655275}\n",
            "{'epoch': 12, 'batch': 3700, 'loss': 4.924301187669909}\n",
            "{'epoch': 12, 'batch': 3800, 'loss': 4.925024054301413}\n",
            "{'epoch': 12, 'batch': 3900, 'loss': 4.925118639897078}\n",
            "{'epoch': 12, 'batch': 4000, 'loss': 4.9255764536857605}\n",
            "{'epoch': 12, 'batch': 4100, 'loss': 4.926054371042949}\n",
            "{'epoch': 12, 'batch': 4200, 'loss': 4.926171302454812}\n",
            "{'epoch': 12, 'batch': 4300, 'loss': 4.9258922621261245}\n",
            "{'epoch': 12, 'batch': 4400, 'loss': 4.925980824773962}\n",
            "{'epoch': 12, 'batch': 4500, 'loss': 4.926337917221917}\n",
            "{'epoch': 12, 'batch': 4600, 'loss': 4.9264635199049245}\n",
            "{'epoch': 12, 'batch': 4700, 'loss': 4.926709778156686}\n",
            "{'epoch': 12, 'batch': 4800, 'loss': 4.926805007656415}\n",
            "{'epoch': 12, 'batch': 4900, 'loss': 4.927255434211419}\n",
            "{'epoch': 12, 'batch': 5000, 'loss': 4.927246696376801}\n",
            "{'epoch': 12, 'loss': 4.927286213467188, 'epoch_losses len': 13}\n",
            "saving model\n",
            "{'epoch': 13, 'batch': 100, 'loss': 4.887449798583984}\n",
            "{'epoch': 13, 'batch': 200, 'loss': 4.8920293402671815}\n",
            "{'epoch': 13, 'batch': 300, 'loss': 4.887485888799032}\n",
            "{'epoch': 13, 'batch': 400, 'loss': 4.894159035682678}\n",
            "{'epoch': 13, 'batch': 500, 'loss': 4.898558195114136}\n",
            "{'epoch': 13, 'batch': 600, 'loss': 4.901021843751272}\n",
            "{'epoch': 13, 'batch': 700, 'loss': 4.9005527557645525}\n",
            "{'epoch': 13, 'batch': 800, 'loss': 4.901606723666191}\n",
            "{'epoch': 13, 'batch': 900, 'loss': 4.900794577068753}\n",
            "{'epoch': 13, 'batch': 1000, 'loss': 4.900867638111115}\n",
            "{'epoch': 13, 'batch': 1100, 'loss': 4.902726600820368}\n",
            "{'epoch': 13, 'batch': 1200, 'loss': 4.902546606063843}\n",
            "{'epoch': 13, 'batch': 1300, 'loss': 4.9029909669435945}\n",
            "{'epoch': 13, 'batch': 1400, 'loss': 4.904190107754299}\n",
            "{'epoch': 13, 'batch': 1500, 'loss': 4.904149726231893}\n",
            "{'epoch': 13, 'batch': 1600, 'loss': 4.905393080711365}\n",
            "{'epoch': 13, 'batch': 1700, 'loss': 4.905409067378325}\n",
            "{'epoch': 13, 'batch': 1800, 'loss': 4.906430837843153}\n",
            "{'epoch': 13, 'batch': 1900, 'loss': 4.906580816570081}\n",
            "{'epoch': 13, 'batch': 2000, 'loss': 4.905383337974548}\n",
            "{'epoch': 13, 'batch': 2100, 'loss': 4.904802261307126}\n",
            "{'epoch': 13, 'batch': 2200, 'loss': 4.905507051727988}\n",
            "{'epoch': 13, 'batch': 2300, 'loss': 4.905828943874525}\n",
            "{'epoch': 13, 'batch': 2400, 'loss': 4.905457454522451}\n",
            "{'epoch': 13, 'batch': 2500, 'loss': 4.906239615440368}\n",
            "{'epoch': 13, 'batch': 2600, 'loss': 4.907071165121518}\n",
            "{'epoch': 13, 'batch': 2700, 'loss': 4.908413681100916}\n",
            "{'epoch': 13, 'batch': 2800, 'loss': 4.908747551611492}\n",
            "{'epoch': 13, 'batch': 2900, 'loss': 4.908655693448823}\n",
            "{'epoch': 13, 'batch': 3000, 'loss': 4.909243600845337}\n",
            "{'epoch': 13, 'batch': 3100, 'loss': 4.909063890672499}\n",
            "{'epoch': 13, 'batch': 3200, 'loss': 4.909737235307693}\n",
            "{'epoch': 13, 'batch': 3300, 'loss': 4.909877137270841}\n",
            "{'epoch': 13, 'batch': 3400, 'loss': 4.909916059690364}\n",
            "{'epoch': 13, 'batch': 3500, 'loss': 4.910151940618243}\n",
            "{'epoch': 13, 'batch': 3600, 'loss': 4.910151379903158}\n",
            "{'epoch': 13, 'batch': 3700, 'loss': 4.910549156343615}\n",
            "{'epoch': 13, 'batch': 3800, 'loss': 4.910300249802439}\n",
            "{'epoch': 13, 'batch': 3900, 'loss': 4.910840493593461}\n",
            "{'epoch': 13, 'batch': 4000, 'loss': 4.9114023770093915}\n",
            "{'epoch': 13, 'batch': 4100, 'loss': 4.9115211079760295}\n",
            "{'epoch': 13, 'batch': 4200, 'loss': 4.9114947543825425}\n",
            "{'epoch': 13, 'batch': 4300, 'loss': 4.911643348849097}\n",
            "{'epoch': 13, 'batch': 4400, 'loss': 4.912358059774745}\n",
            "{'epoch': 13, 'batch': 4500, 'loss': 4.912572554270427}\n",
            "{'epoch': 13, 'batch': 4600, 'loss': 4.912506374172542}\n",
            "{'epoch': 13, 'batch': 4700, 'loss': 4.912327224143008}\n",
            "{'epoch': 13, 'batch': 4800, 'loss': 4.9127443052331605}\n",
            "{'epoch': 13, 'batch': 4900, 'loss': 4.9125177693853574}\n",
            "{'epoch': 13, 'batch': 5000, 'loss': 4.912952950763702}\n",
            "{'epoch': 13, 'loss': 4.912957486416139, 'epoch_losses len': 14}\n",
            "saving model\n",
            "{'epoch': 14, 'batch': 100, 'loss': 4.867582402229309}\n",
            "{'epoch': 14, 'batch': 200, 'loss': 4.869748117923737}\n",
            "{'epoch': 14, 'batch': 300, 'loss': 4.873557637532552}\n",
            "{'epoch': 14, 'batch': 400, 'loss': 4.880745542049408}\n",
            "{'epoch': 14, 'batch': 500, 'loss': 4.8871022920608524}\n",
            "{'epoch': 14, 'batch': 600, 'loss': 4.885847204526265}\n",
            "{'epoch': 14, 'batch': 700, 'loss': 4.88511707510267}\n",
            "{'epoch': 14, 'batch': 800, 'loss': 4.882881712317467}\n",
            "{'epoch': 14, 'batch': 900, 'loss': 4.883514032893711}\n",
            "{'epoch': 14, 'batch': 1000, 'loss': 4.886542912960053}\n",
            "{'epoch': 14, 'batch': 1100, 'loss': 4.8892795835841785}\n",
            "{'epoch': 14, 'batch': 1200, 'loss': 4.8884981962045035}\n",
            "{'epoch': 14, 'batch': 1300, 'loss': 4.88991463624514}\n",
            "{'epoch': 14, 'batch': 1400, 'loss': 4.890089384828295}\n",
            "{'epoch': 14, 'batch': 1500, 'loss': 4.890015684127808}\n",
            "{'epoch': 14, 'batch': 1600, 'loss': 4.8904024863243105}\n",
            "{'epoch': 14, 'batch': 1700, 'loss': 4.89075613526737}\n",
            "{'epoch': 14, 'batch': 1800, 'loss': 4.890737122164833}\n",
            "{'epoch': 14, 'batch': 1900, 'loss': 4.890120789377313}\n",
            "{'epoch': 14, 'batch': 2000, 'loss': 4.889984560251236}\n",
            "{'epoch': 14, 'batch': 2100, 'loss': 4.890251603580657}\n",
            "{'epoch': 14, 'batch': 2200, 'loss': 4.89064997586337}\n",
            "{'epoch': 14, 'batch': 2300, 'loss': 4.891782470993373}\n",
            "{'epoch': 14, 'batch': 2400, 'loss': 4.892181368470192}\n",
            "{'epoch': 14, 'batch': 2500, 'loss': 4.891969430351257}\n",
            "{'epoch': 14, 'batch': 2600, 'loss': 4.893025616499094}\n",
            "{'epoch': 14, 'batch': 2700, 'loss': 4.893604152997335}\n",
            "{'epoch': 14, 'batch': 2800, 'loss': 4.893906694991248}\n",
            "{'epoch': 14, 'batch': 2900, 'loss': 4.894504152988565}\n",
            "{'epoch': 14, 'batch': 3000, 'loss': 4.8953232878049215}\n",
            "{'epoch': 14, 'batch': 3100, 'loss': 4.8956345201307725}\n",
            "{'epoch': 14, 'batch': 3200, 'loss': 4.89622339040041}\n",
            "{'epoch': 14, 'batch': 3300, 'loss': 4.896077884182786}\n",
            "{'epoch': 14, 'batch': 3400, 'loss': 4.896044023738188}\n",
            "{'epoch': 14, 'batch': 3500, 'loss': 4.8966187609263825}\n",
            "{'epoch': 14, 'batch': 3600, 'loss': 4.896662488248613}\n",
            "{'epoch': 14, 'batch': 3700, 'loss': 4.896879095902314}\n",
            "{'epoch': 14, 'batch': 3800, 'loss': 4.896898664549777}\n",
            "{'epoch': 14, 'batch': 3900, 'loss': 4.897402293009636}\n",
            "{'epoch': 14, 'batch': 4000, 'loss': 4.897096534013748}\n",
            "{'epoch': 14, 'batch': 4100, 'loss': 4.89719757335942}\n",
            "{'epoch': 14, 'batch': 4200, 'loss': 4.897226179100218}\n",
            "{'epoch': 14, 'batch': 4300, 'loss': 4.897421307674674}\n",
            "{'epoch': 14, 'batch': 4400, 'loss': 4.898311978795312}\n",
            "{'epoch': 14, 'batch': 4500, 'loss': 4.898624564700657}\n",
            "{'epoch': 14, 'batch': 4600, 'loss': 4.898658000904581}\n",
            "{'epoch': 14, 'batch': 4700, 'loss': 4.898645793732176}\n",
            "{'epoch': 14, 'batch': 4800, 'loss': 4.899317893187205}\n",
            "{'epoch': 14, 'batch': 4900, 'loss': 4.899265674668915}\n",
            "{'epoch': 14, 'batch': 5000, 'loss': 4.899275839424133}\n",
            "{'epoch': 14, 'loss': 4.8993050307571675, 'epoch_losses len': 15}\n",
            "saving model\n",
            "{'epoch': 15, 'batch': 100, 'loss': 4.869168438911438}\n",
            "{'epoch': 15, 'batch': 200, 'loss': 4.871321432590484}\n",
            "{'epoch': 15, 'batch': 300, 'loss': 4.87267656326294}\n",
            "{'epoch': 15, 'batch': 400, 'loss': 4.871049839258194}\n",
            "{'epoch': 15, 'batch': 500, 'loss': 4.87093999004364}\n",
            "{'epoch': 15, 'batch': 600, 'loss': 4.87179788351059}\n",
            "{'epoch': 15, 'batch': 700, 'loss': 4.870846750395638}\n",
            "{'epoch': 15, 'batch': 800, 'loss': 4.870058659315109}\n",
            "{'epoch': 15, 'batch': 900, 'loss': 4.870357740190294}\n",
            "{'epoch': 15, 'batch': 1000, 'loss': 4.871031494617462}\n",
            "{'epoch': 15, 'batch': 1100, 'loss': 4.8717992275411435}\n",
            "{'epoch': 15, 'batch': 1200, 'loss': 4.872002334594726}\n",
            "{'epoch': 15, 'batch': 1300, 'loss': 4.871943390186017}\n",
            "{'epoch': 15, 'batch': 1400, 'loss': 4.872751331329345}\n",
            "{'epoch': 15, 'batch': 1500, 'loss': 4.873154869715373}\n",
            "{'epoch': 15, 'batch': 1600, 'loss': 4.873395480513572}\n",
            "{'epoch': 15, 'batch': 1700, 'loss': 4.873700323665843}\n",
            "{'epoch': 15, 'batch': 1800, 'loss': 4.874420959684584}\n",
            "{'epoch': 15, 'batch': 1900, 'loss': 4.875535056214583}\n",
            "{'epoch': 15, 'batch': 2000, 'loss': 4.876593620538712}\n",
            "{'epoch': 15, 'batch': 2100, 'loss': 4.877276715096973}\n",
            "{'epoch': 15, 'batch': 2200, 'loss': 4.878273465199904}\n",
            "{'epoch': 15, 'batch': 2300, 'loss': 4.87856700150863}\n",
            "{'epoch': 15, 'batch': 2400, 'loss': 4.880309870441755}\n",
            "{'epoch': 15, 'batch': 2500, 'loss': 4.880624680900573}\n",
            "{'epoch': 15, 'batch': 2600, 'loss': 4.8811456489562985}\n",
            "{'epoch': 15, 'batch': 2700, 'loss': 4.8816949448762115}\n",
            "{'epoch': 15, 'batch': 2800, 'loss': 4.882204747881208}\n",
            "{'epoch': 15, 'batch': 2900, 'loss': 4.882497075343954}\n",
            "{'epoch': 15, 'batch': 3000, 'loss': 4.883024043083191}\n",
            "{'epoch': 15, 'batch': 3100, 'loss': 4.883352872633165}\n",
            "{'epoch': 15, 'batch': 3200, 'loss': 4.8829930137097834}\n",
            "{'epoch': 15, 'batch': 3300, 'loss': 4.883575734369683}\n",
            "{'epoch': 15, 'batch': 3400, 'loss': 4.884007939731373}\n",
            "{'epoch': 15, 'batch': 3500, 'loss': 4.884106262479509}\n",
            "{'epoch': 15, 'batch': 3600, 'loss': 4.884194515413708}\n",
            "{'epoch': 15, 'batch': 3700, 'loss': 4.8841849620922195}\n",
            "{'epoch': 15, 'batch': 3800, 'loss': 4.884569113630998}\n",
            "{'epoch': 15, 'batch': 3900, 'loss': 4.884573316574096}\n",
            "{'epoch': 15, 'batch': 4000, 'loss': 4.885325420379639}\n",
            "{'epoch': 15, 'batch': 4100, 'loss': 4.8858038089333515}\n",
            "{'epoch': 15, 'batch': 4200, 'loss': 4.886352131139664}\n",
            "{'epoch': 15, 'batch': 4300, 'loss': 4.88596368700959}\n",
            "{'epoch': 15, 'batch': 4400, 'loss': 4.885780902342363}\n",
            "{'epoch': 15, 'batch': 4500, 'loss': 4.886020414246453}\n",
            "{'epoch': 15, 'batch': 4600, 'loss': 4.885941549798717}\n",
            "{'epoch': 15, 'batch': 4700, 'loss': 4.885989863517437}\n",
            "{'epoch': 15, 'batch': 4800, 'loss': 4.886553134520849}\n",
            "{'epoch': 15, 'batch': 4900, 'loss': 4.887434938975743}\n",
            "{'epoch': 15, 'batch': 5000, 'loss': 4.887602354431152}\n",
            "{'epoch': 15, 'loss': 4.887646337930129, 'epoch_losses len': 16}\n",
            "saving model\n",
            "{'epoch': 16, 'batch': 100, 'loss': 4.841676855087281}\n",
            "{'epoch': 16, 'batch': 200, 'loss': 4.846921935081482}\n",
            "{'epoch': 16, 'batch': 300, 'loss': 4.854560402234395}\n",
            "{'epoch': 16, 'batch': 400, 'loss': 4.855259940624237}\n",
            "{'epoch': 16, 'batch': 500, 'loss': 4.855400505065918}\n",
            "{'epoch': 16, 'batch': 600, 'loss': 4.857767970561981}\n",
            "{'epoch': 16, 'batch': 700, 'loss': 4.860332333019802}\n",
            "{'epoch': 16, 'batch': 800, 'loss': 4.862069590687752}\n",
            "{'epoch': 16, 'batch': 900, 'loss': 4.863053619596693}\n",
            "{'epoch': 16, 'batch': 1000, 'loss': 4.861645337581635}\n",
            "{'epoch': 16, 'batch': 1100, 'loss': 4.865058570775119}\n",
            "{'epoch': 16, 'batch': 1200, 'loss': 4.86723550359408}\n",
            "{'epoch': 16, 'batch': 1300, 'loss': 4.868608356989347}\n",
            "{'epoch': 16, 'batch': 1400, 'loss': 4.869377704007285}\n",
            "{'epoch': 16, 'batch': 1500, 'loss': 4.8688750022252405}\n",
            "{'epoch': 16, 'batch': 1600, 'loss': 4.868238970041275}\n",
            "{'epoch': 16, 'batch': 1700, 'loss': 4.8685007821812345}\n",
            "{'epoch': 16, 'batch': 1800, 'loss': 4.869345416492886}\n",
            "{'epoch': 16, 'batch': 1900, 'loss': 4.869225946978519}\n",
            "{'epoch': 16, 'batch': 2000, 'loss': 4.869898169517517}\n",
            "{'epoch': 16, 'batch': 2100, 'loss': 4.870092901502336}\n",
            "{'epoch': 16, 'batch': 2200, 'loss': 4.87042013168335}\n",
            "{'epoch': 16, 'batch': 2300, 'loss': 4.871071317506873}\n",
            "{'epoch': 16, 'batch': 2400, 'loss': 4.871115503311157}\n",
            "{'epoch': 16, 'batch': 2500, 'loss': 4.871242595100403}\n",
            "{'epoch': 16, 'batch': 2600, 'loss': 4.8707680126336905}\n",
            "{'epoch': 16, 'batch': 2700, 'loss': 4.870294891110173}\n",
            "{'epoch': 16, 'batch': 2800, 'loss': 4.870785312822887}\n",
            "{'epoch': 16, 'batch': 2900, 'loss': 4.87132593845499}\n",
            "{'epoch': 16, 'batch': 3000, 'loss': 4.871780909220377}\n",
            "{'epoch': 16, 'batch': 3100, 'loss': 4.872117113451804}\n",
            "{'epoch': 16, 'batch': 3200, 'loss': 4.872371609061957}\n",
            "{'epoch': 16, 'batch': 3300, 'loss': 4.872549555084922}\n",
            "{'epoch': 16, 'batch': 3400, 'loss': 4.872466627008775}\n",
            "{'epoch': 16, 'batch': 3500, 'loss': 4.873300779615129}\n",
            "{'epoch': 16, 'batch': 3600, 'loss': 4.873716793192758}\n",
            "{'epoch': 16, 'batch': 3700, 'loss': 4.873575918867782}\n",
            "{'epoch': 16, 'batch': 3800, 'loss': 4.873780481313404}\n",
            "{'epoch': 16, 'batch': 3900, 'loss': 4.873874746102553}\n",
            "{'epoch': 16, 'batch': 4000, 'loss': 4.874162397503853}\n",
            "{'epoch': 16, 'batch': 4100, 'loss': 4.874142281834672}\n",
            "{'epoch': 16, 'batch': 4200, 'loss': 4.874223282337189}\n",
            "{'epoch': 16, 'batch': 4300, 'loss': 4.8741964251496075}\n",
            "{'epoch': 16, 'batch': 4400, 'loss': 4.87436619346792}\n",
            "{'epoch': 16, 'batch': 4500, 'loss': 4.874527322451273}\n",
            "{'epoch': 16, 'batch': 4600, 'loss': 4.874668451184812}\n",
            "{'epoch': 16, 'batch': 4700, 'loss': 4.875064399090219}\n",
            "{'epoch': 16, 'batch': 4800, 'loss': 4.8750995102524755}\n",
            "{'epoch': 16, 'batch': 4900, 'loss': 4.875419631296275}\n",
            "{'epoch': 16, 'batch': 5000, 'loss': 4.875580807781219}\n",
            "{'epoch': 16, 'loss': 4.875546538129133, 'epoch_losses len': 17}\n",
            "saving model\n",
            "{'epoch': 17, 'batch': 100, 'loss': 4.850728392601013}\n",
            "{'epoch': 17, 'batch': 200, 'loss': 4.8514137768745424}\n",
            "{'epoch': 17, 'batch': 300, 'loss': 4.847964456876119}\n",
            "{'epoch': 17, 'batch': 400, 'loss': 4.8488949465751645}\n",
            "{'epoch': 17, 'batch': 500, 'loss': 4.852121812820434}\n",
            "{'epoch': 17, 'batch': 600, 'loss': 4.852221970558166}\n",
            "{'epoch': 17, 'batch': 700, 'loss': 4.853482119696481}\n",
            "{'epoch': 17, 'batch': 800, 'loss': 4.856604340076447}\n",
            "{'epoch': 17, 'batch': 900, 'loss': 4.85682171397739}\n",
            "{'epoch': 17, 'batch': 1000, 'loss': 4.856581897258758}\n",
            "{'epoch': 17, 'batch': 1100, 'loss': 4.8567951735583215}\n",
            "{'epoch': 17, 'batch': 1200, 'loss': 4.855793858766556}\n",
            "{'epoch': 17, 'batch': 1300, 'loss': 4.855588178267846}\n",
            "{'epoch': 17, 'batch': 1400, 'loss': 4.8558599843297685}\n",
            "{'epoch': 17, 'batch': 1500, 'loss': 4.855708588282267}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9HnXR8l86mh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "593cc09a-f2ba-409d-89cc-53602a5cd693"
      },
      "source": [
        "print(predict(dataset, model, text='what'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['what', '70', 'price', 'is', 'buying', 'of', 'economic', 'effects', 'here', 'for', 'the', 'npl', 'volume', 'for', 'up', 'was', 'pricing', 'in', 'the', 'big', ',', 'peter', 'feddo', ',', '2019', 'expected', ',', 'while', 'the', 'top', 'president', 'and', 'rent', 'in', 'lieu', 'of', 'the', 'company', \"'\", 'll', 'be', 'met', 'the', 'company', \"'\", 'm', 'looking', 'at', 'approximately', '4', ':', 'abuse', 'and', 'mental', 'region', 'mooning', 'in', 'place', 'again', 'you', 'make', 'holding', '45', '-', 'work', ';', 'estimates', 'in', 'the', 'musk', 'came', 'to', 'make', 'the', 'botox', 'to', 'reflect', 'good', 'signal', ',', 'other', 'people', 'with', 'her', 'accounts', 'and', 'just', 'really', 'stumble', 'significantly', 'on', 'wednesday', ',', 'the', 'resected', 'lung', 'about', 'the', 'world', 'will', 'be']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_CadDaE86mi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b192265-fce7-4970-a365-134c1326146f"
      },
      "source": [
        "print(predict(dataset, model, text='invest in'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['invest', 'in', 'wework', 'got', 'auto', 'manufacturers', 'losing', 'their', 'excess', ',', 'but', '...', 'just', 'like', 'major', 'domestic', 'stimulus', 'is', 'still', 'starting', 'out', 'the', 'cost', '-', 'a', 'out', 'these', 'garbage', 'stocks', 'usually', 'gets', 'circuit', 'breakers', ',', 'all', 'mods', 'can', \"'\", 's', 'consciousness', 'old', 'broker', 'to', 'divest', 'missouri', 'and', 'market', ',', 'which', 'i', 'am', 'going', 'into', 'this', 'year', 'periods', 'of', 'the', 'stock', 'has', 'averaged', 'the', 'fed', 'is', 'traveling', 'by', 'the', 'foot', ',', 'country', ',', 'as', 'extensions', 'of', 'came', 'up', '2', '%', 'from', 'the', 'french', 'king', ',', 'its', 'sss', '188', '.', '**', 'uncertainty', 'hopefully', 'on', 'my', 'taxes', 'on', '&', 'amp', ';', 'q', '=', 'day', 'moving', 'average']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzY6rWiN86mi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e3d7db1-55cd-41e3-c8ea-d0ee936d535d"
      },
      "source": [
        "print(predict(dataset, model, text='deal'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['deal', 'for', 'the', 'mainstream', '-', 'duty', 'or', 'office', '](', 'https', '://', 'imgur', '.', '4', '%', '|', 'lows', 'is', 'in', 'our', 'power', 'are', 'paying', 'for', 'good', 'for', 'the', 'rising', 'relatively', '8', '.', '98', 'shares', ',', 'they', 'expect', '-', '0', '.', 'org', '/', '8', '.', 'change', 'activity', 'for', '$', '2', '.', 'bullish', '25', ')', 'from', 'february', 'the', 'you', 'would', 'be', 'road', 'discuss', 'for', '$', '500', ',', 'seems', 'to', 'get', 'too', 'be', 'close', '|', '+', '0', '.', 'reddit', '.', '1tn', 'their', 'own', 'technical', 'point', 'to', '10', '.', '2', ')', 'is', 'no', 'new', 'zealand', \"'\", 're', 'about', 'both', 'parties', 'and', 'decide', 'from', 'u', '.', '00']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7DR_AjAf1jR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}